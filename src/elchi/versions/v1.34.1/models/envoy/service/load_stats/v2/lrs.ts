// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.7
//   protoc               unknown
// source: envoy/service/load_stats/v2/lrs.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import { Observable } from "rxjs";
import { map } from "rxjs/operators";
import { Duration } from "../../../../google/protobuf/duration";
import { messageTypeRegistry } from "../../../../typeRegistry";
import { Node } from "../../../api/v2/core/base";
import { ClusterStats } from "../../../api/v2/endpoint/load_report";

export const protobufPackage = "envoy.service.load_stats.v2";

/**
 * A load report Envoy sends to the management server.
 * [#not-implemented-hide:] Not configuration. TBD how to doc proto APIs.
 */
export interface LoadStatsRequest {
  $type: "envoy.service.load_stats.v2.LoadStatsRequest";
  /** Node identifier for Envoy instance. */
  node?:
    | Node
    | undefined;
  /** A list of load stats to report. */
  cluster_stats?: ClusterStats[] | undefined;
}

/**
 * The management server sends envoy a LoadStatsResponse with all clusters it
 * is interested in learning load stats about.
 * [#not-implemented-hide:] Not configuration. TBD how to doc proto APIs.
 */
export interface LoadStatsResponse {
  $type: "envoy.service.load_stats.v2.LoadStatsResponse";
  /**
   * Clusters to report stats for.
   * Not populated if *send_all_clusters* is true.
   */
  clusters?:
    | string[]
    | undefined;
  /**
   * If true, the client should send all clusters it knows about.
   * Only clients that advertise the "envoy.lrs.supports_send_all_clusters" capability in their
   * :ref:`client_features<envoy_api_field_core.Node.client_features>` field will honor this field.
   */
  send_all_clusters?:
    | boolean
    | undefined;
  /**
   * The minimum interval of time to collect stats over. This is only a minimum for two reasons:
   * 1. There may be some delay from when the timer fires until stats sampling occurs.
   * 2. For clusters that were already feature in the previous *LoadStatsResponse*, any traffic
   *    that is observed in between the corresponding previous *LoadStatsRequest* and this
   *    *LoadStatsResponse* will also be accumulated and billed to the cluster. This avoids a period
   *    of inobservability that might otherwise exists between the messages. New clusters are not
   *    subject to this consideration.
   */
  load_reporting_interval?:
    | Duration
    | undefined;
  /**
   * Set to *true* if the management server supports endpoint granularity
   * report.
   */
  report_endpoint_granularity?: boolean | undefined;
}

function createBaseLoadStatsRequest(): LoadStatsRequest {
  return { $type: "envoy.service.load_stats.v2.LoadStatsRequest" };
}

export const LoadStatsRequest: MessageFns<LoadStatsRequest, "envoy.service.load_stats.v2.LoadStatsRequest"> = {
  $type: "envoy.service.load_stats.v2.LoadStatsRequest" as const,

  encode(message: LoadStatsRequest, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.node !== undefined) {
      Node.encode(message.node, writer.uint32(10).fork()).join();
    }
    if (message.cluster_stats !== undefined && message.cluster_stats.length !== 0) {
      for (const v of message.cluster_stats) {
        ClusterStats.encode(v!, writer.uint32(18).fork()).join();
      }
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): LoadStatsRequest {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseLoadStatsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.node = Node.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          if (message.cluster_stats === undefined) {
            message.cluster_stats = [];
          }
          const el = ClusterStats.decode(reader, reader.uint32());
          if (el !== undefined) {
            message.cluster_stats!.push(el);
          }
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): LoadStatsRequest {
    return {
      $type: LoadStatsRequest.$type,
      node: isSet(object.node) ? Node.fromJSON(object.node) : undefined,
      cluster_stats: globalThis.Array.isArray(object?.cluster_stats)
        ? object.cluster_stats.map((e: any) => ClusterStats.fromJSON(e))
        : undefined,
    };
  },

  toJSON(message: LoadStatsRequest): unknown {
    const obj: any = {};
    if (message.node !== undefined) {
      obj.node = Node.toJSON(message.node);
    }
    if (message.cluster_stats?.length) {
      obj.cluster_stats = message.cluster_stats.map((e) => ClusterStats.toJSON(e));
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<LoadStatsRequest>, I>>(base?: I): LoadStatsRequest {
    return LoadStatsRequest.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<LoadStatsRequest>, I>>(object: I): LoadStatsRequest {
    const message = createBaseLoadStatsRequest();
    message.node = (object.node !== undefined && object.node !== null) ? Node.fromPartial(object.node) : undefined;
    message.cluster_stats = object.cluster_stats?.map((e) => ClusterStats.fromPartial(e)) || undefined;
    return message;
  },
};

messageTypeRegistry.set(LoadStatsRequest.$type, LoadStatsRequest);

function createBaseLoadStatsResponse(): LoadStatsResponse {
  return { $type: "envoy.service.load_stats.v2.LoadStatsResponse" };
}

export const LoadStatsResponse: MessageFns<LoadStatsResponse, "envoy.service.load_stats.v2.LoadStatsResponse"> = {
  $type: "envoy.service.load_stats.v2.LoadStatsResponse" as const,

  encode(message: LoadStatsResponse, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.clusters !== undefined && message.clusters.length !== 0) {
      for (const v of message.clusters) {
        writer.uint32(10).string(v!);
      }
    }
    if (message.send_all_clusters !== undefined && message.send_all_clusters !== false) {
      writer.uint32(32).bool(message.send_all_clusters);
    }
    if (message.load_reporting_interval !== undefined) {
      Duration.encode(message.load_reporting_interval, writer.uint32(18).fork()).join();
    }
    if (message.report_endpoint_granularity !== undefined && message.report_endpoint_granularity !== false) {
      writer.uint32(24).bool(message.report_endpoint_granularity);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): LoadStatsResponse {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseLoadStatsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          if (message.clusters === undefined) {
            message.clusters = [];
          }
          const el = reader.string();
          if (el !== undefined) {
            message.clusters!.push(el);
          }
          continue;
        }
        case 4: {
          if (tag !== 32) {
            break;
          }

          message.send_all_clusters = reader.bool();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.load_reporting_interval = Duration.decode(reader, reader.uint32());
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.report_endpoint_granularity = reader.bool();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): LoadStatsResponse {
    return {
      $type: LoadStatsResponse.$type,
      clusters: globalThis.Array.isArray(object?.clusters)
        ? object.clusters.map((e: any) => globalThis.String(e))
        : undefined,
      send_all_clusters: isSet(object.send_all_clusters) ? globalThis.Boolean(object.send_all_clusters) : undefined,
      load_reporting_interval: isSet(object.load_reporting_interval)
        ? Duration.fromJSON(object.load_reporting_interval)
        : undefined,
      report_endpoint_granularity: isSet(object.report_endpoint_granularity)
        ? globalThis.Boolean(object.report_endpoint_granularity)
        : undefined,
    };
  },

  toJSON(message: LoadStatsResponse): unknown {
    const obj: any = {};
    if (message.clusters?.length) {
      obj.clusters = message.clusters;
    }
    if (message.send_all_clusters !== undefined) {
      obj.send_all_clusters = message.send_all_clusters;
    }
    if (message.load_reporting_interval !== undefined) {
      obj.load_reporting_interval = Duration.toJSON(message.load_reporting_interval);
    }
    if (message.report_endpoint_granularity !== undefined) {
      obj.report_endpoint_granularity = message.report_endpoint_granularity;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<LoadStatsResponse>, I>>(base?: I): LoadStatsResponse {
    return LoadStatsResponse.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<LoadStatsResponse>, I>>(object: I): LoadStatsResponse {
    const message = createBaseLoadStatsResponse();
    message.clusters = object.clusters?.map((e) => e) || undefined;
    message.send_all_clusters = object.send_all_clusters ?? undefined;
    message.load_reporting_interval =
      (object.load_reporting_interval !== undefined && object.load_reporting_interval !== null)
        ? Duration.fromPartial(object.load_reporting_interval)
        : undefined;
    message.report_endpoint_granularity = object.report_endpoint_granularity ?? undefined;
    return message;
  },
};

messageTypeRegistry.set(LoadStatsResponse.$type, LoadStatsResponse);

export interface LoadReportingService {
  /**
   * Advanced API to allow for multi-dimensional load balancing by remote
   * server. For receiving LB assignments, the steps are:
   * 1, The management server is configured with per cluster/zone/load metric
   *    capacity configuration. The capacity configuration definition is
   *    outside of the scope of this document.
   * 2. Envoy issues a standard {Stream,Fetch}Endpoints request for the clusters
   *    to balance.
   *
   * Independently, Envoy will initiate a StreamLoadStats bidi stream with a
   * management server:
   * 1. Once a connection establishes, the management server publishes a
   *    LoadStatsResponse for all clusters it is interested in learning load
   *    stats about.
   * 2. For each cluster, Envoy load balances incoming traffic to upstream hosts
   *    based on per-zone weights and/or per-instance weights (if specified)
   *    based on intra-zone LbPolicy. This information comes from the above
   *    {Stream,Fetch}Endpoints.
   * 3. When upstream hosts reply, they optionally add header <define header
   *    name> with ASCII representation of EndpointLoadMetricStats.
   * 4. Envoy aggregates load reports over the period of time given to it in
   *    LoadStatsResponse.load_reporting_interval. This includes aggregation
   *    stats Envoy maintains by itself (total_requests, rpc_errors etc.) as
   *    well as load metrics from upstream hosts.
   * 5. When the timer of load_reporting_interval expires, Envoy sends new
   *    LoadStatsRequest filled with load reports for each cluster.
   * 6. The management server uses the load reports from all reported Envoys
   *    from around the world, computes global assignment and prepares traffic
   *    assignment destined for each zone Envoys are located in. Goto 2.
   */
  StreamLoadStats(request: Observable<LoadStatsRequest>): Observable<LoadStatsResponse>;
}

export const LoadReportingServiceServiceName = "envoy.service.load_stats.v2.LoadReportingService";
export class LoadReportingServiceClientImpl implements LoadReportingService {
  private readonly rpc: Rpc;
  private readonly service: string;
  constructor(rpc: Rpc, opts?: { service?: string }) {
    this.service = opts?.service || LoadReportingServiceServiceName;
    this.rpc = rpc;
    this.StreamLoadStats = this.StreamLoadStats.bind(this);
  }
  StreamLoadStats(request: Observable<LoadStatsRequest>): Observable<LoadStatsResponse> {
    const data = request.pipe(map((request) => LoadStatsRequest.encode(request).finish()));
    const result = this.rpc.bidirectionalStreamingRequest(this.service, "StreamLoadStats", data);
    return result.pipe(map((data) => LoadStatsResponse.decode(new BinaryReader(data))));
  }
}

interface Rpc {
  request(service: string, method: string, data: Uint8Array): Promise<Uint8Array>;
  clientStreamingRequest(service: string, method: string, data: Observable<Uint8Array>): Promise<Uint8Array>;
  serverStreamingRequest(service: string, method: string, data: Uint8Array): Observable<Uint8Array>;
  bidirectionalStreamingRequest(service: string, method: string, data: Observable<Uint8Array>): Observable<Uint8Array>;
}

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends { $case: string } ? { [K in keyof Omit<T, "$case">]?: DeepPartial<T[K]> } & { $case: T["$case"] }
  : T extends {} ? { [K in Exclude<keyof T, "$type">]?: DeepPartial<T[K]> }
  : Partial<T>;

type KeysOfUnion<T> = T extends T ? keyof T : never;
export type Exact<P, I extends P> = P extends Builtin ? P
  : P & { [K in keyof P]: Exact<P[K], I[K]> } & { [K in Exclude<keyof I, KeysOfUnion<P> | "$type">]: never };

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T, V extends string> {
  readonly $type: V;
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create<I extends Exact<DeepPartial<T>, I>>(base?: I): T;
  fromPartial<I extends Exact<DeepPartial<T>, I>>(object: I): T;
}
