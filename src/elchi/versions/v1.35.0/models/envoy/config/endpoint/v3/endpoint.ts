// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.7
//   protoc               unknown
// source: envoy/config/endpoint/v3/endpoint.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import { Duration } from "../../../../google/protobuf/duration";
import { UInt32Value } from "../../../../google/protobuf/wrappers";
import { messageTypeRegistry } from "../../../../typeRegistry";
import { FractionalPercent } from "../../../type/v3/percent";
import { Endpoint, LocalityLbEndpoints } from "./endpoint_components";

export const protobufPackage = "envoy.config.endpoint.v3";

/**
 * Each route from RDS will map to a single cluster or traffic split across
 * clusters using weights expressed in the RDS WeightedCluster.
 *
 * With EDS, each cluster is treated independently from a LB perspective, with
 * LB taking place between the Localities within a cluster and at a finer
 * granularity between the hosts within a locality. The percentage of traffic
 * for each endpoint is determined by both its load_balancing_weight, and the
 * load_balancing_weight of its locality. First, a locality will be selected,
 * then an endpoint within that locality will be chose based on its weight.
 * [#next-free-field: 6]
 */
export interface ClusterLoadAssignment {
  $type: "envoy.config.endpoint.v3.ClusterLoadAssignment";
  /**
   * Name of the cluster. This will be the :ref:`service_name
   * <envoy_v3_api_field_config.cluster.v3.Cluster.EdsClusterConfig.service_name>` value if specified
   * in the cluster :ref:`EdsClusterConfig
   * <envoy_v3_api_msg_config.cluster.v3.Cluster.EdsClusterConfig>`.
   */
  cluster_name?:
    | string
    | undefined;
  /** List of endpoints to load balance to. */
  endpoints?:
    | LocalityLbEndpoints[]
    | undefined;
  /**
   * Map of named endpoints that can be referenced in LocalityLbEndpoints.
   * [#not-implemented-hide:]
   */
  named_endpoints?:
    | Map<string, Endpoint>
    | undefined;
  /** Load balancing policy settings. */
  policy?: ClusterLoadAssignment_Policy | undefined;
}

/**
 * Load balancing policy settings.
 * [#next-free-field: 7]
 */
export interface ClusterLoadAssignment_Policy {
  $type: "envoy.config.endpoint.v3.ClusterLoadAssignment.Policy";
  /**
   * Action to trim the overall incoming traffic to protect the upstream
   * hosts. This action allows protection in case the hosts are unable to
   * recover from an outage, or unable to autoscale or unable to handle
   * incoming traffic volume for any reason.
   *
   * At the client each category is applied one after the other to generate
   * the 'actual' drop percentage on all outgoing traffic. For example:
   *
   * .. code-block:: json
   *
   *  { "drop_overloads": [
   *      { "category": "throttle", "drop_percentage": 60 }
   *      { "category": "lb", "drop_percentage": 50 }
   *  ]}
   *
   * The actual drop percentages applied to the traffic at the clients will be
   *    "throttle"_drop = 60%
   *    "lb"_drop = 20%  // 50% of the remaining 'actual' load, which is 40%.
   *    actual_outgoing_load = 20% // remaining after applying all categories.
   *
   * Envoy supports only one element and will NACK if more than one element is present.
   * Other xDS-capable data planes will not necessarily have this limitation.
   *
   * In Envoy, this ``drop_overloads`` config can be overridden by a runtime key
   * "load_balancing_policy.drop_overload_limit" setting. This runtime key can be set to
   * any integer number between 0 and 100. 0 means drop 0%. 100 means drop 100%.
   * When both ``drop_overloads`` config and "load_balancing_policy.drop_overload_limit"
   * setting are in place, the min of these two wins.
   */
  drop_overloads?:
    | ClusterLoadAssignment_Policy_DropOverload[]
    | undefined;
  /**
   * Priority levels and localities are considered overprovisioned with this
   * factor (in percentage). This means that we don't consider a priority
   * level or locality unhealthy until the fraction of healthy hosts
   * multiplied by the overprovisioning factor drops below 100.
   * With the default value 140(1.4), Envoy doesn't consider a priority level
   * or a locality unhealthy until their percentage of healthy hosts drops
   * below 72%. For example:
   *
   * .. code-block:: json
   *
   *  { "overprovisioning_factor": 100 }
   *
   * Read more at :ref:`priority levels <arch_overview_load_balancing_priority_levels>` and
   * :ref:`localities <arch_overview_load_balancing_locality_weighted_lb>`.
   */
  overprovisioning_factor?:
    | number
    | undefined;
  /**
   * The max time until which the endpoints from this assignment can be used.
   * If no new assignments are received before this time expires the endpoints
   * are considered stale and should be marked unhealthy.
   * Defaults to 0 which means endpoints never go stale.
   */
  endpoint_stale_after?:
    | Duration
    | undefined;
  /**
   * If true, use the :ref:`load balancing weight
   * <envoy_v3_api_field_config.endpoint.v3.LbEndpoint.load_balancing_weight>` of healthy and unhealthy
   * hosts to determine the health of the priority level. If false, use the number of healthy and unhealthy hosts
   * to determine the health of the priority level, or in other words assume each host has a weight of 1 for
   * this calculation.
   *
   * .. note::
   *   This is not currently implemented for
   *   :ref:`locality weighted load balancing <arch_overview_load_balancing_locality_weighted_lb>`.
   */
  weighted_priority_health?: boolean | undefined;
}

export interface ClusterLoadAssignment_Policy_DropOverload {
  $type: "envoy.config.endpoint.v3.ClusterLoadAssignment.Policy.DropOverload";
  /** Identifier for the policy specifying the drop. */
  category?:
    | string
    | undefined;
  /** Percentage of traffic that should be dropped for the category. */
  drop_percentage?: FractionalPercent | undefined;
}

export interface ClusterLoadAssignment_NamedEndpointsEntry {
  $type: "envoy.config.endpoint.v3.ClusterLoadAssignment.NamedEndpointsEntry";
  key: string;
  value?: Endpoint | undefined;
}

function createBaseClusterLoadAssignment(): ClusterLoadAssignment {
  return { $type: "envoy.config.endpoint.v3.ClusterLoadAssignment" };
}

export const ClusterLoadAssignment: MessageFns<
  ClusterLoadAssignment,
  "envoy.config.endpoint.v3.ClusterLoadAssignment"
> = {
  $type: "envoy.config.endpoint.v3.ClusterLoadAssignment" as const,

  encode(message: ClusterLoadAssignment, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.cluster_name !== undefined && message.cluster_name !== "") {
      writer.uint32(10).string(message.cluster_name);
    }
    if (message.endpoints !== undefined && message.endpoints.length !== 0) {
      for (const v of message.endpoints) {
        LocalityLbEndpoints.encode(v!, writer.uint32(18).fork()).join();
      }
    }
    (message.named_endpoints || new Map()).forEach((value, key) => {
      ClusterLoadAssignment_NamedEndpointsEntry.encode({
        $type: "envoy.config.endpoint.v3.ClusterLoadAssignment.NamedEndpointsEntry",
        key: key as any,
        value,
      }, writer.uint32(42).fork()).join();
    });
    if (message.policy !== undefined) {
      ClusterLoadAssignment_Policy.encode(message.policy, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ClusterLoadAssignment {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseClusterLoadAssignment();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.cluster_name = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          if (message.endpoints === undefined) {
            message.endpoints = [];
          }
          const el = LocalityLbEndpoints.decode(reader, reader.uint32());
          if (el !== undefined) {
            message.endpoints!.push(el);
          }
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          const entry5 = ClusterLoadAssignment_NamedEndpointsEntry.decode(reader, reader.uint32());
          if (entry5.value !== undefined) {
            if (message.named_endpoints === undefined) {
              message.named_endpoints = new Map();
            }
            message.named_endpoints!.set(entry5.key, entry5.value);
          }
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.policy = ClusterLoadAssignment_Policy.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ClusterLoadAssignment {
    return {
      $type: ClusterLoadAssignment.$type,
      cluster_name: isSet(object.cluster_name) ? globalThis.String(object.cluster_name) : undefined,
      endpoints: globalThis.Array.isArray(object?.endpoints)
        ? object.endpoints.map((e: any) => LocalityLbEndpoints.fromJSON(e))
        : undefined,
      named_endpoints: isObject(object.named_endpoints)
        ? Object.entries(object.named_endpoints).reduce<Map<string, Endpoint>>((acc, [key, value]) => {
          acc.set(key, Endpoint.fromJSON(value));
          return acc;
        }, new Map())
        : undefined,
      policy: isSet(object.policy) ? ClusterLoadAssignment_Policy.fromJSON(object.policy) : undefined,
    };
  },

  toJSON(message: ClusterLoadAssignment): unknown {
    const obj: any = {};
    if (message.cluster_name !== undefined) {
      obj.cluster_name = message.cluster_name;
    }
    if (message.endpoints?.length) {
      obj.endpoints = message.endpoints.map((e) => LocalityLbEndpoints.toJSON(e));
    }
    if (message.named_endpoints?.size) {
      obj.named_endpoints = {};
      message.named_endpoints.forEach((v, k) => {
        obj.named_endpoints[k] = Endpoint.toJSON(v);
      });
    }
    if (message.policy !== undefined) {
      obj.policy = ClusterLoadAssignment_Policy.toJSON(message.policy);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<ClusterLoadAssignment>, I>>(base?: I): ClusterLoadAssignment {
    return ClusterLoadAssignment.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ClusterLoadAssignment>, I>>(object: I): ClusterLoadAssignment {
    const message = createBaseClusterLoadAssignment();
    message.cluster_name = object.cluster_name ?? undefined;
    message.endpoints = object.endpoints?.map((e) => LocalityLbEndpoints.fromPartial(e)) || undefined;
    message.named_endpoints = (object.named_endpoints === undefined || object.named_endpoints === null)
      ? undefined
      : (() => {
        const m = new Map();
        (object.named_endpoints as Map<string, Endpoint> ?? new Map()).forEach((value, key) => {
          if (value !== undefined) {
            m.set(key, Endpoint.fromPartial(value));
          }
        });
        return m;
      })();
    message.policy = (object.policy !== undefined && object.policy !== null)
      ? ClusterLoadAssignment_Policy.fromPartial(object.policy)
      : undefined;
    return message;
  },
};

messageTypeRegistry.set(ClusterLoadAssignment.$type, ClusterLoadAssignment);

function createBaseClusterLoadAssignment_Policy(): ClusterLoadAssignment_Policy {
  return { $type: "envoy.config.endpoint.v3.ClusterLoadAssignment.Policy" };
}

export const ClusterLoadAssignment_Policy: MessageFns<
  ClusterLoadAssignment_Policy,
  "envoy.config.endpoint.v3.ClusterLoadAssignment.Policy"
> = {
  $type: "envoy.config.endpoint.v3.ClusterLoadAssignment.Policy" as const,

  encode(message: ClusterLoadAssignment_Policy, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.drop_overloads !== undefined && message.drop_overloads.length !== 0) {
      for (const v of message.drop_overloads) {
        ClusterLoadAssignment_Policy_DropOverload.encode(v!, writer.uint32(18).fork()).join();
      }
    }
    if (message.overprovisioning_factor !== undefined) {
      UInt32Value.encode(
        { $type: "google.protobuf.UInt32Value", value: message.overprovisioning_factor! },
        writer.uint32(26).fork(),
      ).join();
    }
    if (message.endpoint_stale_after !== undefined) {
      Duration.encode(message.endpoint_stale_after, writer.uint32(34).fork()).join();
    }
    if (message.weighted_priority_health !== undefined && message.weighted_priority_health !== false) {
      writer.uint32(48).bool(message.weighted_priority_health);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ClusterLoadAssignment_Policy {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseClusterLoadAssignment_Policy();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2: {
          if (tag !== 18) {
            break;
          }

          if (message.drop_overloads === undefined) {
            message.drop_overloads = [];
          }
          const el = ClusterLoadAssignment_Policy_DropOverload.decode(reader, reader.uint32());
          if (el !== undefined) {
            message.drop_overloads!.push(el);
          }
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.overprovisioning_factor = UInt32Value.decode(reader, reader.uint32()).value;
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.endpoint_stale_after = Duration.decode(reader, reader.uint32());
          continue;
        }
        case 6: {
          if (tag !== 48) {
            break;
          }

          message.weighted_priority_health = reader.bool();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ClusterLoadAssignment_Policy {
    return {
      $type: ClusterLoadAssignment_Policy.$type,
      drop_overloads: globalThis.Array.isArray(object?.drop_overloads)
        ? object.drop_overloads.map((e: any) => ClusterLoadAssignment_Policy_DropOverload.fromJSON(e))
        : undefined,
      overprovisioning_factor: isSet(object.overprovisioning_factor)
        ? Number(object.overprovisioning_factor)
        : undefined,
      endpoint_stale_after: isSet(object.endpoint_stale_after)
        ? Duration.fromJSON(object.endpoint_stale_after)
        : undefined,
      weighted_priority_health: isSet(object.weighted_priority_health)
        ? globalThis.Boolean(object.weighted_priority_health)
        : undefined,
    };
  },

  toJSON(message: ClusterLoadAssignment_Policy): unknown {
    const obj: any = {};
    if (message.drop_overloads?.length) {
      obj.drop_overloads = message.drop_overloads.map((e) => ClusterLoadAssignment_Policy_DropOverload.toJSON(e));
    }
    if (message.overprovisioning_factor !== undefined) {
      obj.overprovisioning_factor = message.overprovisioning_factor;
    }
    if (message.endpoint_stale_after !== undefined) {
      obj.endpoint_stale_after = Duration.toJSON(message.endpoint_stale_after);
    }
    if (message.weighted_priority_health !== undefined) {
      obj.weighted_priority_health = message.weighted_priority_health;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<ClusterLoadAssignment_Policy>, I>>(base?: I): ClusterLoadAssignment_Policy {
    return ClusterLoadAssignment_Policy.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ClusterLoadAssignment_Policy>, I>>(object: I): ClusterLoadAssignment_Policy {
    const message = createBaseClusterLoadAssignment_Policy();
    message.drop_overloads =
      object.drop_overloads?.map((e) => ClusterLoadAssignment_Policy_DropOverload.fromPartial(e)) || undefined;
    message.overprovisioning_factor = object.overprovisioning_factor ?? undefined;
    message.endpoint_stale_after = (object.endpoint_stale_after !== undefined && object.endpoint_stale_after !== null)
      ? Duration.fromPartial(object.endpoint_stale_after)
      : undefined;
    message.weighted_priority_health = object.weighted_priority_health ?? undefined;
    return message;
  },
};

messageTypeRegistry.set(ClusterLoadAssignment_Policy.$type, ClusterLoadAssignment_Policy);

function createBaseClusterLoadAssignment_Policy_DropOverload(): ClusterLoadAssignment_Policy_DropOverload {
  return { $type: "envoy.config.endpoint.v3.ClusterLoadAssignment.Policy.DropOverload" };
}

export const ClusterLoadAssignment_Policy_DropOverload: MessageFns<
  ClusterLoadAssignment_Policy_DropOverload,
  "envoy.config.endpoint.v3.ClusterLoadAssignment.Policy.DropOverload"
> = {
  $type: "envoy.config.endpoint.v3.ClusterLoadAssignment.Policy.DropOverload" as const,

  encode(message: ClusterLoadAssignment_Policy_DropOverload, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.category !== undefined && message.category !== "") {
      writer.uint32(10).string(message.category);
    }
    if (message.drop_percentage !== undefined) {
      FractionalPercent.encode(message.drop_percentage, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ClusterLoadAssignment_Policy_DropOverload {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseClusterLoadAssignment_Policy_DropOverload();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.category = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.drop_percentage = FractionalPercent.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ClusterLoadAssignment_Policy_DropOverload {
    return {
      $type: ClusterLoadAssignment_Policy_DropOverload.$type,
      category: isSet(object.category) ? globalThis.String(object.category) : undefined,
      drop_percentage: isSet(object.drop_percentage) ? FractionalPercent.fromJSON(object.drop_percentage) : undefined,
    };
  },

  toJSON(message: ClusterLoadAssignment_Policy_DropOverload): unknown {
    const obj: any = {};
    if (message.category !== undefined) {
      obj.category = message.category;
    }
    if (message.drop_percentage !== undefined) {
      obj.drop_percentage = FractionalPercent.toJSON(message.drop_percentage);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<ClusterLoadAssignment_Policy_DropOverload>, I>>(
    base?: I,
  ): ClusterLoadAssignment_Policy_DropOverload {
    return ClusterLoadAssignment_Policy_DropOverload.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ClusterLoadAssignment_Policy_DropOverload>, I>>(
    object: I,
  ): ClusterLoadAssignment_Policy_DropOverload {
    const message = createBaseClusterLoadAssignment_Policy_DropOverload();
    message.category = object.category ?? undefined;
    message.drop_percentage = (object.drop_percentage !== undefined && object.drop_percentage !== null)
      ? FractionalPercent.fromPartial(object.drop_percentage)
      : undefined;
    return message;
  },
};

messageTypeRegistry.set(ClusterLoadAssignment_Policy_DropOverload.$type, ClusterLoadAssignment_Policy_DropOverload);

function createBaseClusterLoadAssignment_NamedEndpointsEntry(): ClusterLoadAssignment_NamedEndpointsEntry {
  return { $type: "envoy.config.endpoint.v3.ClusterLoadAssignment.NamedEndpointsEntry", key: "" };
}

export const ClusterLoadAssignment_NamedEndpointsEntry: MessageFns<
  ClusterLoadAssignment_NamedEndpointsEntry,
  "envoy.config.endpoint.v3.ClusterLoadAssignment.NamedEndpointsEntry"
> = {
  $type: "envoy.config.endpoint.v3.ClusterLoadAssignment.NamedEndpointsEntry" as const,

  encode(message: ClusterLoadAssignment_NamedEndpointsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== undefined) {
      Endpoint.encode(message.value, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ClusterLoadAssignment_NamedEndpointsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseClusterLoadAssignment_NamedEndpointsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = Endpoint.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ClusterLoadAssignment_NamedEndpointsEntry {
    return {
      $type: ClusterLoadAssignment_NamedEndpointsEntry.$type,
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? Endpoint.fromJSON(object.value) : undefined,
    };
  },

  toJSON(message: ClusterLoadAssignment_NamedEndpointsEntry): unknown {
    const obj: any = {};
    if (message.key !== undefined) {
      obj.key = message.key;
    }
    if (message.value !== undefined) {
      obj.value = Endpoint.toJSON(message.value);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<ClusterLoadAssignment_NamedEndpointsEntry>, I>>(
    base?: I,
  ): ClusterLoadAssignment_NamedEndpointsEntry {
    return ClusterLoadAssignment_NamedEndpointsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ClusterLoadAssignment_NamedEndpointsEntry>, I>>(
    object: I,
  ): ClusterLoadAssignment_NamedEndpointsEntry {
    const message = createBaseClusterLoadAssignment_NamedEndpointsEntry();
    message.key = object.key ?? "";
    message.value = (object.value !== undefined && object.value !== null)
      ? Endpoint.fromPartial(object.value)
      : undefined;
    return message;
  },
};

messageTypeRegistry.set(ClusterLoadAssignment_NamedEndpointsEntry.$type, ClusterLoadAssignment_NamedEndpointsEntry);

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends { $case: string } ? { [K in keyof Omit<T, "$case">]?: DeepPartial<T[K]> } & { $case: T["$case"] }
  : T extends {} ? { [K in Exclude<keyof T, "$type">]?: DeepPartial<T[K]> }
  : Partial<T>;

type KeysOfUnion<T> = T extends T ? keyof T : never;
export type Exact<P, I extends P> = P extends Builtin ? P
  : P & { [K in keyof P]: Exact<P[K], I[K]> } & { [K in Exclude<keyof I, KeysOfUnion<P> | "$type">]: never };

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T, V extends string> {
  readonly $type: V;
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create<I extends Exact<DeepPartial<T>, I>>(base?: I): T;
  fromPartial<I extends Exact<DeepPartial<T>, I>>(object: I): T;
}
