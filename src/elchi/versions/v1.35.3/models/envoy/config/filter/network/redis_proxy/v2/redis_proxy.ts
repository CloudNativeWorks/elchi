// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.7
//   protoc               unknown
// source: envoy/config/filter/network/redis_proxy/v2/redis_proxy.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import { Duration } from "../../../../../../google/protobuf/duration";
import { UInt32Value } from "../../../../../../google/protobuf/wrappers";
import { messageTypeRegistry } from "../../../../../../typeRegistry";
import { DataSource, RuntimeFractionalPercent } from "../../../../../api/v2/core/base";

export const protobufPackage = "envoy.config.filter.network.redis_proxy.v2";

/** [#next-free-field: 7] */
export interface RedisProxy {
  $type: "envoy.config.filter.network.redis_proxy.v2.RedisProxy";
  /** The prefix to use when emitting :ref:`statistics <config_network_filters_redis_proxy_stats>`. */
  stat_prefix?:
    | string
    | undefined;
  /**
   * Name of cluster from cluster manager. See the :ref:`configuration section
   * <arch_overview_redis_configuration>` of the architecture overview for recommendations on
   * configuring the backing cluster.
   *
   * .. attention::
   *
   *   This field is deprecated. Use a :ref:`catch_all
   *   route<envoy_api_field_config.filter.network.redis_proxy.v2.RedisProxy.PrefixRoutes.catch_all_route>`
   *   instead.
   *
   * @deprecated
   */
  cluster?:
    | string
    | undefined;
  /** Network settings for the connection pool to the upstream clusters. */
  settings?:
    | RedisProxy_ConnPoolSettings
    | undefined;
  /**
   * Indicates that latency stat should be computed in microseconds. By default it is computed in
   * milliseconds.
   */
  latency_in_micros?:
    | boolean
    | undefined;
  /**
   * List of **unique** prefixes used to separate keys from different workloads to different
   * clusters. Envoy will always favor the longest match first in case of overlap. A catch-all
   * cluster can be used to forward commands when there is no match. Time complexity of the
   * lookups are in O(min(longest key prefix, key length)).
   *
   * Example:
   *
   * .. code-block:: yaml
   *
   *    prefix_routes:
   *      routes:
   *        - prefix: "ab"
   *          cluster: "cluster_a"
   *        - prefix: "abc"
   *          cluster: "cluster_b"
   *
   * When using the above routes, the following prefixes would be sent to:
   *
   * * ``get abc:users`` would retrieve the key 'abc:users' from cluster_b.
   * * ``get ab:users`` would retrieve the key 'ab:users' from cluster_a.
   * * ``get z:users`` would return a NoUpstreamHost error. A :ref:`catch-all
   *   route<envoy_api_field_config.filter.network.redis_proxy.v2.RedisProxy.PrefixRoutes.catch_all_route>`
   *   would have retrieved the key from that cluster instead.
   *
   * See the :ref:`configuration section
   * <arch_overview_redis_configuration>` of the architecture overview for recommendations on
   * configuring the backing clusters.
   */
  prefix_routes?:
    | RedisProxy_PrefixRoutes
    | undefined;
  /**
   * Authenticate Redis client connections locally by forcing downstream clients to issue a `Redis
   * AUTH command <https://redis.io/commands/auth>`_ with this password before enabling any other
   * command. If an AUTH command's password matches this password, an "OK" response will be returned
   * to the client. If the AUTH command password does not match this password, then an "ERR invalid
   * password" error will be returned. If any other command is received before AUTH when this
   * password is set, then a "NOAUTH Authentication required." error response will be sent to the
   * client. If an AUTH command is received when the password is not set, then an "ERR Client sent
   * AUTH, but no password is set" error will be returned.
   */
  downstream_auth_password?: DataSource | undefined;
}

/**
 * Redis connection pool settings.
 * [#next-free-field: 9]
 */
export interface RedisProxy_ConnPoolSettings {
  $type: "envoy.config.filter.network.redis_proxy.v2.RedisProxy.ConnPoolSettings";
  /**
   * Per-operation timeout in milliseconds. The timer starts when the first
   * command of a pipeline is written to the backend connection. Each response received from Redis
   * resets the timer since it signifies that the next command is being processed by the backend.
   * The only exception to this behavior is when a connection to a backend is not yet established.
   * In that case, the connect timeout on the cluster will govern the timeout until the connection
   * is ready.
   */
  op_timeout?:
    | Duration
    | undefined;
  /**
   * Use hash tagging on every redis key to guarantee that keys with the same hash tag will be
   * forwarded to the same upstream. The hash key used for determining the upstream in a
   * consistent hash ring configuration will be computed from the hash tagged key instead of the
   * whole key. The algorithm used to compute the hash tag is identical to the `redis-cluster
   * implementation <https://redis.io/topics/cluster-spec#keys-hash-tags>`_.
   *
   * Examples:
   *
   * * '{user1000}.following' and '{user1000}.followers' **will** be sent to the same upstream
   * * '{user1000}.following' and '{user1001}.following' **might** be sent to the same upstream
   */
  enable_hashtagging?:
    | boolean
    | undefined;
  /**
   * Accept `moved and ask redirection
   * <https://redis.io/topics/cluster-spec#redirection-and-resharding>`_ errors from upstream
   * redis servers, and retry commands to the specified target server. The target server does not
   * need to be known to the cluster manager. If the command cannot be redirected, then the
   * original error is passed downstream unchanged. By default, this support is not enabled.
   */
  enable_redirection?:
    | boolean
    | undefined;
  /**
   * Maximum size of encoded request buffer before flush is triggered and encoded requests
   * are sent upstream. If this is unset, the buffer flushes whenever it receives data
   * and performs no batching.
   * This feature makes it possible for multiple clients to send requests to Envoy and have
   * them batched- for example if one is running several worker processes, each with its own
   * Redis connection. There is no benefit to using this with a single downstream process.
   * Recommended size (if enabled) is 1024 bytes.
   */
  max_buffer_size_before_flush?:
    | number
    | undefined;
  /**
   * The encoded request buffer is flushed N milliseconds after the first request has been
   * encoded, unless the buffer size has already exceeded `max_buffer_size_before_flush`.
   * If `max_buffer_size_before_flush` is not set, this flush timer is not used. Otherwise,
   * the timer should be set according to the number of clients, overall request rate and
   * desired maximum latency for a single command. For example, if there are many requests
   * being batched together at a high rate, the buffer will likely be filled before the timer
   * fires. Alternatively, if the request rate is lower the buffer will not be filled as often
   * before the timer fires.
   * If `max_buffer_size_before_flush` is set, but `buffer_flush_timeout` is not, the latter
   * defaults to 3ms.
   */
  buffer_flush_timeout?:
    | Duration
    | undefined;
  /**
   * `max_upstream_unknown_connections` controls how many upstream connections to unknown hosts
   * can be created at any given time by any given worker thread (see `enable_redirection` for
   * more details). If the host is unknown and a connection cannot be created due to enforcing
   * this limit, then redirection will fail and the original redirection error will be passed
   * downstream unchanged. This limit defaults to 100.
   */
  max_upstream_unknown_connections?:
    | number
    | undefined;
  /**
   * Enable per-command statistics per upstream cluster, in addition to the filter level aggregate
   * count.
   */
  enable_command_stats?:
    | boolean
    | undefined;
  /** Read policy. The default is to read from the primary. */
  read_policy?: RedisProxy_ConnPoolSettings_ReadPolicy | undefined;
}

/**
 * ReadPolicy controls how Envoy routes read commands to Redis nodes. This is currently
 * supported for Redis Cluster. All ReadPolicy settings except MASTER may return stale data
 * because replication is asynchronous and requires some delay. You need to ensure that your
 * application can tolerate stale data.
 */
export enum RedisProxy_ConnPoolSettings_ReadPolicy {
  /** MASTER - Default mode. Read from the current primary node. */
  MASTER = "MASTER",
  /** PREFER_MASTER - Read from the primary, but if it is unavailable, read from replica nodes. */
  PREFER_MASTER = "PREFER_MASTER",
  /**
   * REPLICA - Read from replica nodes. If multiple replica nodes are present within a shard, a random
   * node is selected. Healthy nodes have precedent over unhealthy nodes.
   */
  REPLICA = "REPLICA",
  /**
   * PREFER_REPLICA - Read from the replica nodes (similar to REPLICA), but if all replicas are unavailable (not
   * present or unhealthy), read from the primary.
   */
  PREFER_REPLICA = "PREFER_REPLICA",
  /**
   * ANY - Read from any node of the cluster. A random node is selected among the primary and
   * replicas, healthy nodes have precedent over unhealthy nodes.
   */
  ANY = "ANY",
}

export function redisProxy_ConnPoolSettings_ReadPolicyFromJSON(object: any): RedisProxy_ConnPoolSettings_ReadPolicy {
  switch (object) {
    case 0:
    case "MASTER":
      return RedisProxy_ConnPoolSettings_ReadPolicy.MASTER;
    case 1:
    case "PREFER_MASTER":
      return RedisProxy_ConnPoolSettings_ReadPolicy.PREFER_MASTER;
    case 2:
    case "REPLICA":
      return RedisProxy_ConnPoolSettings_ReadPolicy.REPLICA;
    case 3:
    case "PREFER_REPLICA":
      return RedisProxy_ConnPoolSettings_ReadPolicy.PREFER_REPLICA;
    case 4:
    case "ANY":
      return RedisProxy_ConnPoolSettings_ReadPolicy.ANY;
    default:
      throw new globalThis.Error(
        "Unrecognized enum value " + object + " for enum RedisProxy_ConnPoolSettings_ReadPolicy",
      );
  }
}

export function redisProxy_ConnPoolSettings_ReadPolicyToJSON(object: RedisProxy_ConnPoolSettings_ReadPolicy): string {
  switch (object) {
    case RedisProxy_ConnPoolSettings_ReadPolicy.MASTER:
      return "MASTER";
    case RedisProxy_ConnPoolSettings_ReadPolicy.PREFER_MASTER:
      return "PREFER_MASTER";
    case RedisProxy_ConnPoolSettings_ReadPolicy.REPLICA:
      return "REPLICA";
    case RedisProxy_ConnPoolSettings_ReadPolicy.PREFER_REPLICA:
      return "PREFER_REPLICA";
    case RedisProxy_ConnPoolSettings_ReadPolicy.ANY:
      return "ANY";
    default:
      throw new globalThis.Error(
        "Unrecognized enum value " + object + " for enum RedisProxy_ConnPoolSettings_ReadPolicy",
      );
  }
}

export function redisProxy_ConnPoolSettings_ReadPolicyToNumber(object: RedisProxy_ConnPoolSettings_ReadPolicy): number {
  switch (object) {
    case RedisProxy_ConnPoolSettings_ReadPolicy.MASTER:
      return 0;
    case RedisProxy_ConnPoolSettings_ReadPolicy.PREFER_MASTER:
      return 1;
    case RedisProxy_ConnPoolSettings_ReadPolicy.REPLICA:
      return 2;
    case RedisProxy_ConnPoolSettings_ReadPolicy.PREFER_REPLICA:
      return 3;
    case RedisProxy_ConnPoolSettings_ReadPolicy.ANY:
      return 4;
    default:
      throw new globalThis.Error(
        "Unrecognized enum value " + object + " for enum RedisProxy_ConnPoolSettings_ReadPolicy",
      );
  }
}

export interface RedisProxy_PrefixRoutes {
  $type: "envoy.config.filter.network.redis_proxy.v2.RedisProxy.PrefixRoutes";
  /** List of prefix routes. */
  routes?:
    | RedisProxy_PrefixRoutes_Route[]
    | undefined;
  /** Indicates that prefix matching should be case insensitive. */
  case_insensitive?:
    | boolean
    | undefined;
  /**
   * Optional catch-all route to forward commands that doesn't match any of the routes. The
   * catch-all route becomes required when no routes are specified.
   * .. attention::
   *
   *   This field is deprecated. Use a :ref:`catch_all
   *   route<envoy_api_field_config.filter.network.redis_proxy.v2.RedisProxy.PrefixRoutes.catch_all_route>`
   *   instead.
   *
   * @deprecated
   */
  catch_all_cluster?:
    | string
    | undefined;
  /**
   * Optional catch-all route to forward commands that doesn't match any of the routes. The
   * catch-all route becomes required when no routes are specified.
   */
  catch_all_route?: RedisProxy_PrefixRoutes_Route | undefined;
}

export interface RedisProxy_PrefixRoutes_Route {
  $type: "envoy.config.filter.network.redis_proxy.v2.RedisProxy.PrefixRoutes.Route";
  /**
   * String prefix that must match the beginning of the keys. Envoy will always favor the
   * longest match.
   */
  prefix?:
    | string
    | undefined;
  /** Indicates if the prefix needs to be removed from the key when forwarded. */
  remove_prefix?:
    | boolean
    | undefined;
  /** Upstream cluster to forward the command to. */
  cluster?:
    | string
    | undefined;
  /** Indicates that the route has a request mirroring policy. */
  request_mirror_policy?: RedisProxy_PrefixRoutes_Route_RequestMirrorPolicy[] | undefined;
}

/**
 * The router is capable of shadowing traffic from one cluster to another. The current
 * implementation is "fire and forget," meaning Envoy will not wait for the shadow cluster to
 * respond before returning the response from the primary cluster. All normal statistics are
 * collected for the shadow cluster making this feature useful for testing.
 */
export interface RedisProxy_PrefixRoutes_Route_RequestMirrorPolicy {
  $type: "envoy.config.filter.network.redis_proxy.v2.RedisProxy.PrefixRoutes.Route.RequestMirrorPolicy";
  /**
   * Specifies the cluster that requests will be mirrored to. The cluster must
   * exist in the cluster manager configuration.
   */
  cluster?:
    | string
    | undefined;
  /**
   * If not specified or the runtime key is not present, all requests to the target cluster
   * will be mirrored.
   *
   * If specified, Envoy will lookup the runtime key to get the percentage of requests to the
   * mirror.
   */
  runtime_fraction?:
    | RuntimeFractionalPercent
    | undefined;
  /**
   * Set this to TRUE to only mirror write commands, this is effectively replicating the
   * writes in a "fire and forget" manner.
   */
  exclude_read_commands?: boolean | undefined;
}

/**
 * RedisProtocolOptions specifies Redis upstream protocol options. This object is used in
 * :ref:`typed_extension_protocol_options<envoy_api_field_Cluster.typed_extension_protocol_options>`,
 * keyed by the name `envoy.filters.network.redis_proxy`.
 */
export interface RedisProtocolOptions {
  $type: "envoy.config.filter.network.redis_proxy.v2.RedisProtocolOptions";
  /**
   * Upstream server password as defined by the `requirepass` directive
   * <https://redis.io/topics/config>`_ in the server's configuration file.
   */
  auth_password?: DataSource | undefined;
}

function createBaseRedisProxy(): RedisProxy {
  return { $type: "envoy.config.filter.network.redis_proxy.v2.RedisProxy" };
}

export const RedisProxy: MessageFns<RedisProxy, "envoy.config.filter.network.redis_proxy.v2.RedisProxy"> = {
  $type: "envoy.config.filter.network.redis_proxy.v2.RedisProxy" as const,

  encode(message: RedisProxy, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.stat_prefix !== undefined && message.stat_prefix !== "") {
      writer.uint32(10).string(message.stat_prefix);
    }
    if (message.cluster !== undefined && message.cluster !== "") {
      writer.uint32(18).string(message.cluster);
    }
    if (message.settings !== undefined) {
      RedisProxy_ConnPoolSettings.encode(message.settings, writer.uint32(26).fork()).join();
    }
    if (message.latency_in_micros !== undefined && message.latency_in_micros !== false) {
      writer.uint32(32).bool(message.latency_in_micros);
    }
    if (message.prefix_routes !== undefined) {
      RedisProxy_PrefixRoutes.encode(message.prefix_routes, writer.uint32(42).fork()).join();
    }
    if (message.downstream_auth_password !== undefined) {
      DataSource.encode(message.downstream_auth_password, writer.uint32(50).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RedisProxy {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRedisProxy();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.stat_prefix = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.cluster = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.settings = RedisProxy_ConnPoolSettings.decode(reader, reader.uint32());
          continue;
        }
        case 4: {
          if (tag !== 32) {
            break;
          }

          message.latency_in_micros = reader.bool();
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.prefix_routes = RedisProxy_PrefixRoutes.decode(reader, reader.uint32());
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.downstream_auth_password = DataSource.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RedisProxy {
    return {
      $type: RedisProxy.$type,
      stat_prefix: isSet(object.stat_prefix) ? globalThis.String(object.stat_prefix) : undefined,
      cluster: isSet(object.cluster) ? globalThis.String(object.cluster) : undefined,
      settings: isSet(object.settings) ? RedisProxy_ConnPoolSettings.fromJSON(object.settings) : undefined,
      latency_in_micros: isSet(object.latency_in_micros) ? globalThis.Boolean(object.latency_in_micros) : undefined,
      prefix_routes: isSet(object.prefix_routes) ? RedisProxy_PrefixRoutes.fromJSON(object.prefix_routes) : undefined,
      downstream_auth_password: isSet(object.downstream_auth_password)
        ? DataSource.fromJSON(object.downstream_auth_password)
        : undefined,
    };
  },

  toJSON(message: RedisProxy): unknown {
    const obj: any = {};
    if (message.stat_prefix !== undefined) {
      obj.stat_prefix = message.stat_prefix;
    }
    if (message.cluster !== undefined) {
      obj.cluster = message.cluster;
    }
    if (message.settings !== undefined) {
      obj.settings = RedisProxy_ConnPoolSettings.toJSON(message.settings);
    }
    if (message.latency_in_micros !== undefined) {
      obj.latency_in_micros = message.latency_in_micros;
    }
    if (message.prefix_routes !== undefined) {
      obj.prefix_routes = RedisProxy_PrefixRoutes.toJSON(message.prefix_routes);
    }
    if (message.downstream_auth_password !== undefined) {
      obj.downstream_auth_password = DataSource.toJSON(message.downstream_auth_password);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<RedisProxy>, I>>(base?: I): RedisProxy {
    return RedisProxy.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<RedisProxy>, I>>(object: I): RedisProxy {
    const message = createBaseRedisProxy();
    message.stat_prefix = object.stat_prefix ?? undefined;
    message.cluster = object.cluster ?? undefined;
    message.settings = (object.settings !== undefined && object.settings !== null)
      ? RedisProxy_ConnPoolSettings.fromPartial(object.settings)
      : undefined;
    message.latency_in_micros = object.latency_in_micros ?? undefined;
    message.prefix_routes = (object.prefix_routes !== undefined && object.prefix_routes !== null)
      ? RedisProxy_PrefixRoutes.fromPartial(object.prefix_routes)
      : undefined;
    message.downstream_auth_password =
      (object.downstream_auth_password !== undefined && object.downstream_auth_password !== null)
        ? DataSource.fromPartial(object.downstream_auth_password)
        : undefined;
    return message;
  },
};

messageTypeRegistry.set(RedisProxy.$type, RedisProxy);

function createBaseRedisProxy_ConnPoolSettings(): RedisProxy_ConnPoolSettings {
  return { $type: "envoy.config.filter.network.redis_proxy.v2.RedisProxy.ConnPoolSettings" };
}

export const RedisProxy_ConnPoolSettings: MessageFns<
  RedisProxy_ConnPoolSettings,
  "envoy.config.filter.network.redis_proxy.v2.RedisProxy.ConnPoolSettings"
> = {
  $type: "envoy.config.filter.network.redis_proxy.v2.RedisProxy.ConnPoolSettings" as const,

  encode(message: RedisProxy_ConnPoolSettings, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.op_timeout !== undefined) {
      Duration.encode(message.op_timeout, writer.uint32(10).fork()).join();
    }
    if (message.enable_hashtagging !== undefined && message.enable_hashtagging !== false) {
      writer.uint32(16).bool(message.enable_hashtagging);
    }
    if (message.enable_redirection !== undefined && message.enable_redirection !== false) {
      writer.uint32(24).bool(message.enable_redirection);
    }
    if (message.max_buffer_size_before_flush !== undefined && message.max_buffer_size_before_flush !== 0) {
      writer.uint32(32).uint32(message.max_buffer_size_before_flush);
    }
    if (message.buffer_flush_timeout !== undefined) {
      Duration.encode(message.buffer_flush_timeout, writer.uint32(42).fork()).join();
    }
    if (message.max_upstream_unknown_connections !== undefined) {
      UInt32Value.encode(
        { $type: "google.protobuf.UInt32Value", value: message.max_upstream_unknown_connections! },
        writer.uint32(50).fork(),
      ).join();
    }
    if (message.enable_command_stats !== undefined && message.enable_command_stats !== false) {
      writer.uint32(64).bool(message.enable_command_stats);
    }
    if (message.read_policy !== undefined && message.read_policy !== RedisProxy_ConnPoolSettings_ReadPolicy.MASTER) {
      writer.uint32(56).int32(redisProxy_ConnPoolSettings_ReadPolicyToNumber(message.read_policy));
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RedisProxy_ConnPoolSettings {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRedisProxy_ConnPoolSettings();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.op_timeout = Duration.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.enable_hashtagging = reader.bool();
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.enable_redirection = reader.bool();
          continue;
        }
        case 4: {
          if (tag !== 32) {
            break;
          }

          message.max_buffer_size_before_flush = reader.uint32();
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.buffer_flush_timeout = Duration.decode(reader, reader.uint32());
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.max_upstream_unknown_connections = UInt32Value.decode(reader, reader.uint32()).value;
          continue;
        }
        case 8: {
          if (tag !== 64) {
            break;
          }

          message.enable_command_stats = reader.bool();
          continue;
        }
        case 7: {
          if (tag !== 56) {
            break;
          }

          message.read_policy = redisProxy_ConnPoolSettings_ReadPolicyFromJSON(reader.int32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RedisProxy_ConnPoolSettings {
    return {
      $type: RedisProxy_ConnPoolSettings.$type,
      op_timeout: isSet(object.op_timeout) ? Duration.fromJSON(object.op_timeout) : undefined,
      enable_hashtagging: isSet(object.enable_hashtagging) ? globalThis.Boolean(object.enable_hashtagging) : undefined,
      enable_redirection: isSet(object.enable_redirection) ? globalThis.Boolean(object.enable_redirection) : undefined,
      max_buffer_size_before_flush: isSet(object.max_buffer_size_before_flush)
        ? globalThis.Number(object.max_buffer_size_before_flush)
        : undefined,
      buffer_flush_timeout: isSet(object.buffer_flush_timeout)
        ? Duration.fromJSON(object.buffer_flush_timeout)
        : undefined,
      max_upstream_unknown_connections: isSet(object.max_upstream_unknown_connections)
        ? Number(object.max_upstream_unknown_connections)
        : undefined,
      enable_command_stats: isSet(object.enable_command_stats)
        ? globalThis.Boolean(object.enable_command_stats)
        : undefined,
      read_policy: isSet(object.read_policy)
        ? redisProxy_ConnPoolSettings_ReadPolicyFromJSON(object.read_policy)
        : undefined,
    };
  },

  toJSON(message: RedisProxy_ConnPoolSettings): unknown {
    const obj: any = {};
    if (message.op_timeout !== undefined) {
      obj.op_timeout = Duration.toJSON(message.op_timeout);
    }
    if (message.enable_hashtagging !== undefined) {
      obj.enable_hashtagging = message.enable_hashtagging;
    }
    if (message.enable_redirection !== undefined) {
      obj.enable_redirection = message.enable_redirection;
    }
    if (message.max_buffer_size_before_flush !== undefined) {
      obj.max_buffer_size_before_flush = Math.round(message.max_buffer_size_before_flush);
    }
    if (message.buffer_flush_timeout !== undefined) {
      obj.buffer_flush_timeout = Duration.toJSON(message.buffer_flush_timeout);
    }
    if (message.max_upstream_unknown_connections !== undefined) {
      obj.max_upstream_unknown_connections = message.max_upstream_unknown_connections;
    }
    if (message.enable_command_stats !== undefined) {
      obj.enable_command_stats = message.enable_command_stats;
    }
    if (message.read_policy !== undefined) {
      obj.read_policy = redisProxy_ConnPoolSettings_ReadPolicyToJSON(message.read_policy);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<RedisProxy_ConnPoolSettings>, I>>(base?: I): RedisProxy_ConnPoolSettings {
    return RedisProxy_ConnPoolSettings.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<RedisProxy_ConnPoolSettings>, I>>(object: I): RedisProxy_ConnPoolSettings {
    const message = createBaseRedisProxy_ConnPoolSettings();
    message.op_timeout = (object.op_timeout !== undefined && object.op_timeout !== null)
      ? Duration.fromPartial(object.op_timeout)
      : undefined;
    message.enable_hashtagging = object.enable_hashtagging ?? undefined;
    message.enable_redirection = object.enable_redirection ?? undefined;
    message.max_buffer_size_before_flush = object.max_buffer_size_before_flush ?? undefined;
    message.buffer_flush_timeout = (object.buffer_flush_timeout !== undefined && object.buffer_flush_timeout !== null)
      ? Duration.fromPartial(object.buffer_flush_timeout)
      : undefined;
    message.max_upstream_unknown_connections = object.max_upstream_unknown_connections ?? undefined;
    message.enable_command_stats = object.enable_command_stats ?? undefined;
    message.read_policy = object.read_policy ?? undefined;
    return message;
  },
};

messageTypeRegistry.set(RedisProxy_ConnPoolSettings.$type, RedisProxy_ConnPoolSettings);

function createBaseRedisProxy_PrefixRoutes(): RedisProxy_PrefixRoutes {
  return { $type: "envoy.config.filter.network.redis_proxy.v2.RedisProxy.PrefixRoutes" };
}

export const RedisProxy_PrefixRoutes: MessageFns<
  RedisProxy_PrefixRoutes,
  "envoy.config.filter.network.redis_proxy.v2.RedisProxy.PrefixRoutes"
> = {
  $type: "envoy.config.filter.network.redis_proxy.v2.RedisProxy.PrefixRoutes" as const,

  encode(message: RedisProxy_PrefixRoutes, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.routes !== undefined && message.routes.length !== 0) {
      for (const v of message.routes) {
        RedisProxy_PrefixRoutes_Route.encode(v!, writer.uint32(10).fork()).join();
      }
    }
    if (message.case_insensitive !== undefined && message.case_insensitive !== false) {
      writer.uint32(16).bool(message.case_insensitive);
    }
    if (message.catch_all_cluster !== undefined && message.catch_all_cluster !== "") {
      writer.uint32(26).string(message.catch_all_cluster);
    }
    if (message.catch_all_route !== undefined) {
      RedisProxy_PrefixRoutes_Route.encode(message.catch_all_route, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RedisProxy_PrefixRoutes {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRedisProxy_PrefixRoutes();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          if (message.routes === undefined) {
            message.routes = [];
          }
          const el = RedisProxy_PrefixRoutes_Route.decode(reader, reader.uint32());
          if (el !== undefined) {
            message.routes!.push(el);
          }
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.case_insensitive = reader.bool();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.catch_all_cluster = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.catch_all_route = RedisProxy_PrefixRoutes_Route.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RedisProxy_PrefixRoutes {
    return {
      $type: RedisProxy_PrefixRoutes.$type,
      routes: globalThis.Array.isArray(object?.routes)
        ? object.routes.map((e: any) => RedisProxy_PrefixRoutes_Route.fromJSON(e))
        : undefined,
      case_insensitive: isSet(object.case_insensitive) ? globalThis.Boolean(object.case_insensitive) : undefined,
      catch_all_cluster: isSet(object.catch_all_cluster) ? globalThis.String(object.catch_all_cluster) : undefined,
      catch_all_route: isSet(object.catch_all_route)
        ? RedisProxy_PrefixRoutes_Route.fromJSON(object.catch_all_route)
        : undefined,
    };
  },

  toJSON(message: RedisProxy_PrefixRoutes): unknown {
    const obj: any = {};
    if (message.routes?.length) {
      obj.routes = message.routes.map((e) => RedisProxy_PrefixRoutes_Route.toJSON(e));
    }
    if (message.case_insensitive !== undefined) {
      obj.case_insensitive = message.case_insensitive;
    }
    if (message.catch_all_cluster !== undefined) {
      obj.catch_all_cluster = message.catch_all_cluster;
    }
    if (message.catch_all_route !== undefined) {
      obj.catch_all_route = RedisProxy_PrefixRoutes_Route.toJSON(message.catch_all_route);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<RedisProxy_PrefixRoutes>, I>>(base?: I): RedisProxy_PrefixRoutes {
    return RedisProxy_PrefixRoutes.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<RedisProxy_PrefixRoutes>, I>>(object: I): RedisProxy_PrefixRoutes {
    const message = createBaseRedisProxy_PrefixRoutes();
    message.routes = object.routes?.map((e) => RedisProxy_PrefixRoutes_Route.fromPartial(e)) || undefined;
    message.case_insensitive = object.case_insensitive ?? undefined;
    message.catch_all_cluster = object.catch_all_cluster ?? undefined;
    message.catch_all_route = (object.catch_all_route !== undefined && object.catch_all_route !== null)
      ? RedisProxy_PrefixRoutes_Route.fromPartial(object.catch_all_route)
      : undefined;
    return message;
  },
};

messageTypeRegistry.set(RedisProxy_PrefixRoutes.$type, RedisProxy_PrefixRoutes);

function createBaseRedisProxy_PrefixRoutes_Route(): RedisProxy_PrefixRoutes_Route {
  return { $type: "envoy.config.filter.network.redis_proxy.v2.RedisProxy.PrefixRoutes.Route" };
}

export const RedisProxy_PrefixRoutes_Route: MessageFns<
  RedisProxy_PrefixRoutes_Route,
  "envoy.config.filter.network.redis_proxy.v2.RedisProxy.PrefixRoutes.Route"
> = {
  $type: "envoy.config.filter.network.redis_proxy.v2.RedisProxy.PrefixRoutes.Route" as const,

  encode(message: RedisProxy_PrefixRoutes_Route, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.prefix !== undefined && message.prefix !== "") {
      writer.uint32(10).string(message.prefix);
    }
    if (message.remove_prefix !== undefined && message.remove_prefix !== false) {
      writer.uint32(16).bool(message.remove_prefix);
    }
    if (message.cluster !== undefined && message.cluster !== "") {
      writer.uint32(26).string(message.cluster);
    }
    if (message.request_mirror_policy !== undefined && message.request_mirror_policy.length !== 0) {
      for (const v of message.request_mirror_policy) {
        RedisProxy_PrefixRoutes_Route_RequestMirrorPolicy.encode(v!, writer.uint32(34).fork()).join();
      }
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RedisProxy_PrefixRoutes_Route {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRedisProxy_PrefixRoutes_Route();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.prefix = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.remove_prefix = reader.bool();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.cluster = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          if (message.request_mirror_policy === undefined) {
            message.request_mirror_policy = [];
          }
          const el = RedisProxy_PrefixRoutes_Route_RequestMirrorPolicy.decode(reader, reader.uint32());
          if (el !== undefined) {
            message.request_mirror_policy!.push(el);
          }
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RedisProxy_PrefixRoutes_Route {
    return {
      $type: RedisProxy_PrefixRoutes_Route.$type,
      prefix: isSet(object.prefix) ? globalThis.String(object.prefix) : undefined,
      remove_prefix: isSet(object.remove_prefix) ? globalThis.Boolean(object.remove_prefix) : undefined,
      cluster: isSet(object.cluster) ? globalThis.String(object.cluster) : undefined,
      request_mirror_policy: globalThis.Array.isArray(object?.request_mirror_policy)
        ? object.request_mirror_policy.map((e: any) => RedisProxy_PrefixRoutes_Route_RequestMirrorPolicy.fromJSON(e))
        : undefined,
    };
  },

  toJSON(message: RedisProxy_PrefixRoutes_Route): unknown {
    const obj: any = {};
    if (message.prefix !== undefined) {
      obj.prefix = message.prefix;
    }
    if (message.remove_prefix !== undefined) {
      obj.remove_prefix = message.remove_prefix;
    }
    if (message.cluster !== undefined) {
      obj.cluster = message.cluster;
    }
    if (message.request_mirror_policy?.length) {
      obj.request_mirror_policy = message.request_mirror_policy.map((e) =>
        RedisProxy_PrefixRoutes_Route_RequestMirrorPolicy.toJSON(e)
      );
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<RedisProxy_PrefixRoutes_Route>, I>>(base?: I): RedisProxy_PrefixRoutes_Route {
    return RedisProxy_PrefixRoutes_Route.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<RedisProxy_PrefixRoutes_Route>, I>>(
    object: I,
  ): RedisProxy_PrefixRoutes_Route {
    const message = createBaseRedisProxy_PrefixRoutes_Route();
    message.prefix = object.prefix ?? undefined;
    message.remove_prefix = object.remove_prefix ?? undefined;
    message.cluster = object.cluster ?? undefined;
    message.request_mirror_policy =
      object.request_mirror_policy?.map((e) => RedisProxy_PrefixRoutes_Route_RequestMirrorPolicy.fromPartial(e)) ||
      undefined;
    return message;
  },
};

messageTypeRegistry.set(RedisProxy_PrefixRoutes_Route.$type, RedisProxy_PrefixRoutes_Route);

function createBaseRedisProxy_PrefixRoutes_Route_RequestMirrorPolicy(): RedisProxy_PrefixRoutes_Route_RequestMirrorPolicy {
  return { $type: "envoy.config.filter.network.redis_proxy.v2.RedisProxy.PrefixRoutes.Route.RequestMirrorPolicy" };
}

export const RedisProxy_PrefixRoutes_Route_RequestMirrorPolicy: MessageFns<
  RedisProxy_PrefixRoutes_Route_RequestMirrorPolicy,
  "envoy.config.filter.network.redis_proxy.v2.RedisProxy.PrefixRoutes.Route.RequestMirrorPolicy"
> = {
  $type: "envoy.config.filter.network.redis_proxy.v2.RedisProxy.PrefixRoutes.Route.RequestMirrorPolicy" as const,

  encode(
    message: RedisProxy_PrefixRoutes_Route_RequestMirrorPolicy,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.cluster !== undefined && message.cluster !== "") {
      writer.uint32(10).string(message.cluster);
    }
    if (message.runtime_fraction !== undefined) {
      RuntimeFractionalPercent.encode(message.runtime_fraction, writer.uint32(18).fork()).join();
    }
    if (message.exclude_read_commands !== undefined && message.exclude_read_commands !== false) {
      writer.uint32(24).bool(message.exclude_read_commands);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RedisProxy_PrefixRoutes_Route_RequestMirrorPolicy {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRedisProxy_PrefixRoutes_Route_RequestMirrorPolicy();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.cluster = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.runtime_fraction = RuntimeFractionalPercent.decode(reader, reader.uint32());
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.exclude_read_commands = reader.bool();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RedisProxy_PrefixRoutes_Route_RequestMirrorPolicy {
    return {
      $type: RedisProxy_PrefixRoutes_Route_RequestMirrorPolicy.$type,
      cluster: isSet(object.cluster) ? globalThis.String(object.cluster) : undefined,
      runtime_fraction: isSet(object.runtime_fraction)
        ? RuntimeFractionalPercent.fromJSON(object.runtime_fraction)
        : undefined,
      exclude_read_commands: isSet(object.exclude_read_commands)
        ? globalThis.Boolean(object.exclude_read_commands)
        : undefined,
    };
  },

  toJSON(message: RedisProxy_PrefixRoutes_Route_RequestMirrorPolicy): unknown {
    const obj: any = {};
    if (message.cluster !== undefined) {
      obj.cluster = message.cluster;
    }
    if (message.runtime_fraction !== undefined) {
      obj.runtime_fraction = RuntimeFractionalPercent.toJSON(message.runtime_fraction);
    }
    if (message.exclude_read_commands !== undefined) {
      obj.exclude_read_commands = message.exclude_read_commands;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<RedisProxy_PrefixRoutes_Route_RequestMirrorPolicy>, I>>(
    base?: I,
  ): RedisProxy_PrefixRoutes_Route_RequestMirrorPolicy {
    return RedisProxy_PrefixRoutes_Route_RequestMirrorPolicy.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<RedisProxy_PrefixRoutes_Route_RequestMirrorPolicy>, I>>(
    object: I,
  ): RedisProxy_PrefixRoutes_Route_RequestMirrorPolicy {
    const message = createBaseRedisProxy_PrefixRoutes_Route_RequestMirrorPolicy();
    message.cluster = object.cluster ?? undefined;
    message.runtime_fraction = (object.runtime_fraction !== undefined && object.runtime_fraction !== null)
      ? RuntimeFractionalPercent.fromPartial(object.runtime_fraction)
      : undefined;
    message.exclude_read_commands = object.exclude_read_commands ?? undefined;
    return message;
  },
};

messageTypeRegistry.set(
  RedisProxy_PrefixRoutes_Route_RequestMirrorPolicy.$type,
  RedisProxy_PrefixRoutes_Route_RequestMirrorPolicy,
);

function createBaseRedisProtocolOptions(): RedisProtocolOptions {
  return { $type: "envoy.config.filter.network.redis_proxy.v2.RedisProtocolOptions" };
}

export const RedisProtocolOptions: MessageFns<
  RedisProtocolOptions,
  "envoy.config.filter.network.redis_proxy.v2.RedisProtocolOptions"
> = {
  $type: "envoy.config.filter.network.redis_proxy.v2.RedisProtocolOptions" as const,

  encode(message: RedisProtocolOptions, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.auth_password !== undefined) {
      DataSource.encode(message.auth_password, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RedisProtocolOptions {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRedisProtocolOptions();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.auth_password = DataSource.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RedisProtocolOptions {
    return {
      $type: RedisProtocolOptions.$type,
      auth_password: isSet(object.auth_password) ? DataSource.fromJSON(object.auth_password) : undefined,
    };
  },

  toJSON(message: RedisProtocolOptions): unknown {
    const obj: any = {};
    if (message.auth_password !== undefined) {
      obj.auth_password = DataSource.toJSON(message.auth_password);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<RedisProtocolOptions>, I>>(base?: I): RedisProtocolOptions {
    return RedisProtocolOptions.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<RedisProtocolOptions>, I>>(object: I): RedisProtocolOptions {
    const message = createBaseRedisProtocolOptions();
    message.auth_password = (object.auth_password !== undefined && object.auth_password !== null)
      ? DataSource.fromPartial(object.auth_password)
      : undefined;
    return message;
  },
};

messageTypeRegistry.set(RedisProtocolOptions.$type, RedisProtocolOptions);

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends { $case: string } ? { [K in keyof Omit<T, "$case">]?: DeepPartial<T[K]> } & { $case: T["$case"] }
  : T extends {} ? { [K in Exclude<keyof T, "$type">]?: DeepPartial<T[K]> }
  : Partial<T>;

type KeysOfUnion<T> = T extends T ? keyof T : never;
export type Exact<P, I extends P> = P extends Builtin ? P
  : P & { [K in keyof P]: Exact<P[K], I[K]> } & { [K in Exclude<keyof I, KeysOfUnion<P> | "$type">]: never };

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T, V extends string> {
  readonly $type: V;
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create<I extends Exact<DeepPartial<T>, I>>(base?: I): T;
  fromPartial<I extends Exact<DeepPartial<T>, I>>(object: I): T;
}
